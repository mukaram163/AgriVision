"""
preprocessing.py
----------------
This file handles all preprocessing tasks for the AgriVision project:
1. Splitting the dataset into train/val/test sets
2. Applying image transformations (resize, flip, rotate, normalize)
3. Creating PyTorch Datasets and DataLoaders

Author: Mukaram Ali
"""

import os
import shutil
import random
from tqdm import tqdm

from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ----------------------------------------------------------
# ðŸ§© 1. Function: Split Dataset into Train / Val / Test
# ----------------------------------------------------------
def split_dataset(source_dir, dest_dir, train_ratio=0.7, val_ratio=0.2, test_ratio=0.1):
    """
    Splits the PlantVillage dataset into train, validation, and test folders.

    Args:
        source_dir (str): Path to raw dataset (e.g., ../data/raw/PlantVillage)
        dest_dir (str): Destination path for processed data (e.g., ../data/processed)
        train_ratio (float): Fraction of data for training
        val_ratio (float): Fraction of data for validation
        test_ratio (float): Fraction of data for testing

    Example:
        split_dataset("../data/raw/PlantVillage", "../data/processed")
    """

    assert abs(train_ratio + val_ratio + test_ratio - 1.0) < 1e-6, "Ratios must sum to 1"

    classes = [d for d in os.listdir(source_dir) if os.path.isdir(os.path.join(source_dir, d))]

    for cls in classes:
        class_dir = os.path.join(source_dir, cls)
        images = os.listdir(class_dir)
        random.shuffle(images)  # randomize image order

        n_total = len(images)
        n_train = int(n_total * train_ratio)
        n_val = int(n_total * val_ratio)

        # Divide image names into splits
        splits = {
            'train': images[:n_train],
            'val': images[n_train:n_train + n_val],
            'test': images[n_train + n_val:]
        }

        # Copy files into respective folders
        for split_name, split_files in splits.items():
            split_dir = os.path.join(dest_dir, split_name, cls)
            os.makedirs(split_dir, exist_ok=True)

            for img in tqdm(split_files, desc=f"{cls} â†’ {split_name}"):
                src_path = os.path.join(class_dir, img)
                dst_path = os.path.join(split_dir, img)
                shutil.copy2(src_path, dst_path)

    print("âœ… Dataset successfully split into train, val, and test folders.")


# ----------------------------------------------------------
# ðŸ§© 2. Function: Define Image Transformations
# ----------------------------------------------------------
def get_transforms(img_size=224):
    """
    Defines image preprocessing and augmentation steps.

    Args:
        img_size (int): Size to resize all images (default 224x224)

    Returns:
        (train_transforms, val_test_transforms)
    """

    train_transforms = transforms.Compose([
        transforms.Resize((img_size, img_size)),       # make all images the same size
        transforms.RandomHorizontalFlip(p=0.5),        # randomly flip horizontally
        transforms.RandomRotation(15),                 # rotate image by Â±15Â°
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),                         # convert to PyTorch tensor
        transforms.Normalize(mean=[0.485, 0.456, 0.406],  # normalize (ImageNet mean/std)
                             std=[0.229, 0.224, 0.225])
    ])

    val_test_transforms = transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    return train_transforms, val_test_transforms


# ----------------------------------------------------------
# ðŸ§© 3. Function: Create Datasets and DataLoaders
# ----------------------------------------------------------
def create_dataloaders(data_dir="../data/processed", batch_size=32, img_size=224):
    """
    Creates train, validation, and test dataloaders for PyTorch.

    Args:
        data_dir (str): Path to processed dataset folder
        batch_size (int): Number of images per batch
        img_size (int): Image resize dimension (default 224)

    Returns:
        train_loader, val_loader, test_loader, class_names
    """

    train_transforms, val_test_transforms = get_transforms(img_size)

    # Create PyTorch datasets using ImageFolder (expects folder/class_name/img.jpg)
    train_dataset = datasets.ImageFolder(os.path.join(data_dir, "train"), transform=train_transforms)
    val_dataset = datasets.ImageFolder(os.path.join(data_dir, "val"), transform=val_test_transforms)
    test_dataset = datasets.ImageFolder(os.path.join(data_dir, "test"), transform=val_test_transforms)

    # Create DataLoaders (PyTorchâ€™s way to feed batches efficiently)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)

    class_names = train_dataset.classes
    print(f"âœ… Datasets ready: {len(train_dataset)} train, {len(val_dataset)} val, {len(test_dataset)} test")
    print(f"Classes: {class_names}")

    return train_loader, val_loader, test_loader, class_names


# ----------------------------------------------------------
# ðŸ§© Example (Run once to split dataset)
# ----------------------------------------------------------
if __name__ == "__main__":
    # This block only runs when you execute: python src/preprocessing.py
    source = "../data/raw/PlantVillage"
    destination = "../data/processed"
    split_dataset(source, destination)